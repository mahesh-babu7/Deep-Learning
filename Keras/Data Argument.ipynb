{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824b5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac98bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('D:\\VS Code\\Keras\\Earth.jpg')  # this is a PIL image\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)  # Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir=r\"D:\\VS Code\\Keras\", save_prefix='earth', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:  # otherwise the generator would loop indefinitely\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Functional name=resnet50, built=True>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights = \"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0566d",
   "metadata": {},
   "source": [
    "# 1. RESNET50 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Predictions:\n",
      "1: jeep (0.51)\n",
      "2: minivan (0.47)\n",
      "3: alp (0.00)\n",
      "\n",
      " Top class index  : 609\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = r'D:\\VS Code\\Keras\\Car.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "decode_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "print(\"Predictions:\")\n",
    "for i, (imagenet_id, label, score) in enumerate(decode_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\n Top class index  : {top_class_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4173bd",
   "metadata": {},
   "source": [
    "# 2. RESNET50V2 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Predictions:\n",
      "1: jeep (0.95)\n",
      "2: minivan (0.03)\n",
      "3: car_wheel (0.01)\n",
      "\n",
      " Top Predictions class index: 609\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet_v2 import  ResNet50V2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50V2(weights='imagenet')\n",
    "\n",
    "img_path = r'D:\\VS Code\\Keras\\Car.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "decode_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "print(\"Predictions:\")\n",
    "for i, (imagenet_id, label, score) in enumerate(decode_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\n Top Predictions class index: {top_class_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f9e9c",
   "metadata": {},
   "source": [
    "# 3. VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028A95B5F100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Predictions:\n",
      "1: jeep (0.67)\n",
      "2: minivan (0.17)\n",
      "3: alp (0.05)\n",
      "\n",
      "Top Prediction Class Index: 609\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet data\n",
    "# model = VGG16(weights='imagenet')\n",
    "model = VGG16(weights=r'D:\\VS Code\\Keras\\vgg16_weights.h5')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replacewith the path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print(\"Predictions:\")\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fa19b",
   "metadata": {},
   "source": [
    "# 4. VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "Predictions:\n",
      "1: jeep (0.35)\n",
      "2: alp (0.18)\n",
      "3: minivan (0.15)\n",
      "\n",
      "Top Prediction Class Index: 609\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the VGG19 model pre-trained on ImageNet data\n",
    "model = VGG19(weights=r'D:\\VS Code\\Keras\\vgg19_weights.h5')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d52ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Predictions:\n",
      "1: jeep (0.35)\n",
      "2: alp (0.18)\n",
      "3: minivan (0.15)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 0.00 ms\n",
      "Size (MB): 548.05 MB\n",
      "Parameters: 143667240\n",
      "Depth: 26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "# Load the VGG19 model pre-trained on ImageNet data\n",
    "model = VGG19(weights=r'D:\\VS Code\\Keras\\vgg19_weights.h5')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef489a",
   "metadata": {},
   "source": [
    "# 5. Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "Predictions:\n",
      "1: jeep (0.68)\n",
      "2: alp (0.12)\n",
      "3: convertible (0.02)\n",
      "4: racer (0.02)\n",
      "5: minivan (0.01)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 7200.37 ms\n",
      "Size (MB): 87.40 MB\n",
      "Parameters: 22910480\n",
      "Depth: 134\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import preprocess_input,decode_predictions\n",
    "\n",
    "# Load the Xception model pre-trained on ImageNet data\n",
    "model = Xception(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with thepath to your image file\n",
    "img = image.load_img(img_path, target_size=(299, 299)) # Xception requires␣input shape (299, 299)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc3b14",
   "metadata": {},
   "source": [
    "# 6. InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m96112376/96112376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "Predictions:\n",
      "1: jeep (0.88)\n",
      "2: alp (0.03)\n",
      "3: valley (0.02)\n",
      "4: cliff (0.00)\n",
      "5: mountain_bike (0.00)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 7184.66 ms\n",
      "Size (MB): 90.99 MB\n",
      "Parameters: 23851784\n",
      "Depth: 313\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input,decode_predictions\n",
    "\n",
    "# Load the InceptionV3 model pre-trained on ImageNet data\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the path to your image file\n",
    "img = image.load_img(img_path, target_size=(299, 299)) # Xception requires␣input shape (299, 299)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf234b6",
   "metadata": {},
   "source": [
    "# 7. MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "\u001b[1m14536120/14536120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predictions:\n",
      "1: jeep (0.81)\n",
      "2: alp (0.05)\n",
      "3: minivan (0.03)\n",
      "4: convertible (0.02)\n",
      "5: pickup (0.01)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 2031.92 ms\n",
      "Size (MB): 13.50 MB\n",
      "Parameters: 3538984\n",
      "Depth: 156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input,decode_predictions\n",
    "\n",
    "# Load the MobileNetV2 model pre-trained on ImageNet data\n",
    "model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the␣path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bfe420",
   "metadata": {},
   "source": [
    "# 8. Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x0000028AD8CD1C60>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Mahesh Babu\\anaconda3\\Lib\\weakref.py\", line 370, in remove\n",
      "    self = selfref()\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m33188688/33188688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "Predictions:\n",
      "1: jeep (0.86)\n",
      "2: minivan (0.11)\n",
      "3: alp (0.01)\n",
      "4: recreational_vehicle (0.01)\n",
      "5: minibus (0.01)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 5870.37 ms\n",
      "Size (MB): 30.76 MB\n",
      "Parameters: 8062504\n",
      "Depth: 429\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the DenseNet121 model pre-trained on ImageNet data\n",
    "model = DenseNet121(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the␣path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f9dc5",
   "metadata": {},
   "source": [
    "# 9. NASNet Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile.h5\n",
      "\u001b[1m24227760/24227760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "Predictions:\n",
      "1: jeep (0.92)\n",
      "2: minivan (0.01)\n",
      "3: alp (0.01)\n",
      "4: cliff (0.00)\n",
      "5: ibex (0.00)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 10377.42 ms\n",
      "Size (MB): 20.32 MB\n",
      "Parameters: 5326716\n",
      "Depth: 771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import NASNetMobile\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the NASNetMobile model pre-trained on ImageNet data\n",
    "model = NASNetMobile(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the␣path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8756f3",
   "metadata": {},
   "source": [
    "# 10. NasaNet Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "Predictions:\n",
      "1: jeep (0.61)\n",
      "2: alp (0.21)\n",
      "3: valley (0.03)\n",
      "4: minivan (0.02)\n",
      "5: cliff (0.01)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 11636.74 ms\n",
      "Size (MB): 339.32 MB\n",
      "Parameters: 88949818\n",
      "Depth: 1041\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input,decode_predictions\n",
    "\n",
    "# Load the NASNetLarge model pre-trained on ImageNet data\n",
    "model = NASNetLarge(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the␣path to your image file\n",
    "img = image.load_img(img_path, target_size=(331, 331))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6af17",
   "metadata": {},
   "source": [
    "# 11. EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0.h5\n",
      "\u001b[1m29403144/29403144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Predictions:\n",
      "1: jeep (0.50)\n",
      "2: alp (0.21)\n",
      "3: valley (0.06)\n",
      "4: minivan (0.02)\n",
      "5: cliff (0.01)\n",
      "\n",
      "Top Prediction Class Index: 609\n",
      "Inference Time: 3899.19 ms\n",
      "Size (MB): 27.47 MB\n",
      "Parameters: 7200312\n",
      "Depth: 273\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input,decode_predictions\n",
    "\n",
    "# Load the EfficientNetV2B0 model pre-trained on ImageNet data\n",
    "model = EfficientNetV2B0(weights='imagenet')\n",
    "\n",
    "# Load and preprocess the input image\n",
    "img_path = r\"D:\\VS Code\\Keras\\Car.jpeg\" # replace with the␣path to your image file\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "\n",
    "# Decode and print the top-3 predicted classes\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print(\"Predictions:\")\n",
    "\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n",
    "    \n",
    "# Optionally, you can obtain the class index for the top prediction\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"\\nTop Prediction Class Index: {top_class_index}\")\n",
    "\n",
    "# Calculate and print the inference time per step\n",
    "inference_time_ms = (end_time - start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "# Model summary provides information about parameters and layers\n",
    "#model.summary()\n",
    "\n",
    "# Get the size of the model in megabytes\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) # 4 bytes for float32\n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the number of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "print(f\"Parameters: {num_parameters}\")\n",
    "print(f\"Depth: {model_depth}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
